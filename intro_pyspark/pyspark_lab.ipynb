{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b4fdc50-d981-4982-a135-f47c84b3972d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set pyspark env variables\n",
    "import os\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'\n",
    "os.environ['PYSPARK_PYTHON'] = 'python'\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb2e2b0d-bbe8-4ccc-b36d-1affd2637ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e102d43-6d55-4020-8f22-2b3410b2ee78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a SparkSession \n",
    "spark = SparkSession.builder.appName(\"Spark-Starter\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d631913-4323-4f89-aca6-1fa3c3d40ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|    Name|Age|\n",
      "+--------+---+\n",
      "|   James| 24|\n",
      "|   Smith| 19|\n",
      "|Williams| 35|\n",
      "+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test set up\n",
    "data = [(\"James\", 24),(\"Smith\", 19),(\"Williams\", 35)]\n",
    "df = spark.createDataFrame(data, [\"Name\",\"Age\"])\n",
    "# Displays the content of the DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d017a58c-d55b-4c7d-bb47-00927cbd89f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shut down SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b182816b-5372-4d0f-99f1-9b027b612274",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SparkContext\n",
    "- Represents the connection to a Spark\n",
    "- Coordinates task execution across the cluster\n",
    "- entry point in earlier version spark (1.x)\n",
    "## SparkSession\n",
    "- Introduced Spark 2.0\n",
    "- Unified entry point for interacting with Spark\n",
    "- Combines Spark/SQL/Hive/Streaming Context\n",
    "- Support multiple API languages (Java, Scala, Python, R)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3aa784-179f-4c1b-a8ec-9f0de2e3ec02",
   "metadata": {},
   "source": [
    "## Create SparkContenxt in Apache Spark Version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50076568-06fb-4463-a02a-b0df98cdec4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import SparkContext from pyspark\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# create a SparkContext object\n",
    "sc = SparkContext(appName=\"SparkContextApp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "730e2bb8-b0c8-4c7e-ad68-7b363af76827",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Yohammed.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkContextApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=SparkContextApp>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a784c726-5e4c-44e1-9756-e903981bcb14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# always remember to stop an existining session/object before starting a new one\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352920d-86fc-4866-a34b-2f710ace1d08",
   "metadata": {},
   "source": [
    "## Create SparkSession in Apache Spark Version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e5d57aa-40b6-4833-a868-5ccd70506570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# create a SparkSession\n",
    "new_spark = SparkSession.builder.appName(\"ApacheSparkApp\").getOrCreate()\n",
    "\n",
    "# Get the SparkContenxt from the SparkSession\n",
    "sc = new_spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aaa2b4c-edb9-480e-9dba-c082d7a6cf78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Yohammed.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ApacheSparkApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=ApacheSparkApp>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd4ca459-1397-4b6d-bdf8-d64d5017a2b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shut down the session\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a967a65b-9cf9-4de9-937e-8b4bda8c6d0e",
   "metadata": {},
   "source": [
    "# Create a new SparkSession and focus on Spark RDD, DataFrame, and computing operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb3924a5-2dea-4c1b-961c-bceeca0e6931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ApacheSparkApp\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb5c7e54-c3c9-4e3f-89e3-6578d8c3dde1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Yohammed.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ApacheSparkApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1f48208b650>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform operation using SparkSession\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "193b074d-ccb8-4ff0-ba0b-aba168010c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# terminate Spark Session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0949a9-4dc3-4d9a-b5e0-99a2d6644d89",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RDD's characteristics\n",
    "- Immutable\n",
    "- Distributed\n",
    "- Resilient\n",
    "- Lazily Evaluated \n",
    "- Fault-tolerant operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a808ba2-ce3f-44da-8851-ca5bad5a7a26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a session that will be use to create and conduct operation via RDDS\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"RDD-Demo\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ca2b2-0883-46d0-a025-1601c6d60a06",
   "metadata": {},
   "source": [
    "# Create RDDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14d0b454-ef96-4565-bba5-d0c870f99cac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Create RDDS\n",
    "numbers = [1,23,-4,52,-5,3,6,19,1,-1,0,10]\n",
    "rdd = spark.sparkContext.parallelize(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38123508-7dff-4b02-9651-2382a1621404",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 23, -4, 52, -5, 3, 6, 19, 1, -1, 0, 10]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the collect function to retrive and display the RDD\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e03af450-fd7d-44ba-8e13-692288427c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create an RDD from a list of tuples\n",
    "data = [('Swimming', 'Phelps'),('Basketball', 'Kobe'),('Boxing', 'Floyed'),('Tennis', 'Serena'),('Basketball', 'Michael'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f1c5602-d6b5-42a5-9069-1fcbea7609a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Swimming', 'Phelps'),\n",
       " ('Basketball', 'Kobe'),\n",
       " ('Boxing', 'Floyed'),\n",
       " ('Tennis', 'Serena'),\n",
       " ('Basketball', 'Michael')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize(data)\n",
    "# print the RDD list\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95f2efa4-0448-4438-9bfc-a8b5a9614513",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kobe is a Basketball player.\n",
      "Michael is a Basketball player.\n"
     ]
    }
   ],
   "source": [
    "# print only the tuples who play basketball\n",
    "for sport, athlete in rdd.collect():\n",
    "    if sport == \"Basketball\":\n",
    "        print(\"{} is a {} player.\".format(athlete, sport))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa67bd86-5b2a-47ca-ab91-a0dd114cac77",
   "metadata": {},
   "source": [
    "## RDDs Operation Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41d2579b-ba06-466e-ad52-0db37a29fd2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of records: 5\n"
     ]
    }
   ],
   "source": [
    "# Display the number of records in the RDDS\n",
    "print(f\"Total Number of records: {rdd.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "052d3933-bc9c-4d08-8946-b8454d38bb65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Swimming', 'Phelps')\n"
     ]
    }
   ],
   "source": [
    "# return first element\n",
    "print(rdd.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e50254a8-e01f-42e1-8378-9bd78bab936e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Basketball', 'Michael')\n"
     ]
    }
   ],
   "source": [
    "# return last element\n",
    "print(rdd.collect()[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc06130-a07e-4aae-9388-e8da696b8503",
   "metadata": {},
   "source": [
    "# RDD TRANSFORMATION\n",
    "(Lazily evaluated which means no transformation will be executed unless an action has been taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f3e7828-fbf0-4df1-b11b-ec7b62f070ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Map transformation to convert the first index in each tupple to all uppercase\n",
    "upper_rdd = rdd.map(lambda x: (x[0], x[1].upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "34df9efe-fcbb-4afe-95e4-a46ce7076b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd with upper case names: [('Swimming', 'PHELPS'), ('Basketball', 'KOBE'), ('Boxing', 'FLOYED'), ('Tennis', 'SERENA'), ('Basketball', 'MICHAEL')]\n"
     ]
    }
   ],
   "source": [
    "# print\n",
    "print(\"rdd with upper case names: {}\".format(upper_rdd.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8b955f-9996-49c2-aa3a-7bef4a5d83fe",
   "metadata": {},
   "source": [
    "## Save the RDD as a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "99ae96e5-79df-41b4-a650-2c1354887f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "print(type(rdd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b040eb4-0fe6-49ad-b53a-b81e25636fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4604304-7fc7-430f-b617-555fb27500af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
